{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Yelp Dataset Preprocessing Exploration\n",
        "\n",
        "This notebook provides an interactive exploration of the data preprocessing pipeline for the LLM-powered Business Improvement Agent project.\n",
        "\n",
        "## Objectives\n",
        "1. **Missing Value Analysis**: Identify and handle missing data across all datasets\n",
        "2. **Duplicate Detection**: Remove exact and near-duplicate records\n",
        "3. **Spam Detection**: Filter out spam and bot-generated reviews\n",
        "4. **Data Consistency**: Standardize formats and validate data quality\n",
        "5. **Quality Assessment**: Generate comprehensive quality reports\n",
        "\n",
        "## Dataset Overview\n",
        "- **Business Data**: Business information, ratings, categories\n",
        "- **Review Data**: User reviews with text and ratings\n",
        "- **User Data**: User profiles and activity\n",
        "- **Tip Data**: Short user tips and recommendations\n",
        "- **Check-in Data**: Business visit patterns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add src directory to path\n",
        "project_root = Path('../').resolve()\n",
        "sys.path.insert(0, str(project_root / \"src\"))\n",
        "\n",
        "# Import our custom preprocessor\n",
        "from data_preprocessor import YelpDataPreprocessor\n",
        "\n",
        "# Set up plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"üöÄ Libraries imported successfully!\")\n",
        "print(f\"üìÅ Project root: {project_root}\")\n",
        "\n",
        "# Initialize preprocessor\n",
        "preprocessor = YelpDataPreprocessor(\n",
        "    raw_data_path=project_root / \"raw_data\",\n",
        "    processed_data_path=project_root / \"data\" / \"processed\"\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Data preprocessor initialized\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load and Explore Raw Data\n",
        "\n",
        "Let's start by loading a sample of each dataset to understand the data structure and identify quality issues.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load sample datasets for exploration\n",
        "print(\"üìÇ Loading sample datasets for exploration...\")\n",
        "\n",
        "# Load smaller samples for interactive exploration\n",
        "datasets = {}\n",
        "sample_sizes = {\n",
        "    'business': 5000,\n",
        "    'review': 10000, \n",
        "    'user': 3000,\n",
        "    'tip': 2000\n",
        "}\n",
        "\n",
        "for dataset_name, sample_size in sample_sizes.items():\n",
        "    try:\n",
        "        print(f\"Loading {dataset_name} ({sample_size:,} records)...\")\n",
        "        df = preprocessor.load_dataset_stream(dataset_name, sample_size)\n",
        "        datasets[dataset_name] = df\n",
        "        print(f\"‚úÖ {dataset_name}: {len(df):,} records loaded\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"‚ö†Ô∏è {dataset_name} dataset not found\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading {dataset_name}: {e}\")\n",
        "\n",
        "print(f\"\\nüìä Successfully loaded {len(datasets)} datasets\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
